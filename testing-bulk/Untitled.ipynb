{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f323fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d21c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = open('/home/rdr2143/darknet/data/coco.names').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5294f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromDarknet('/home/rdr2143/darknet/cfg/yolov2.cfg', '/home/rdr2143/darknet/yolov2.weights')\n",
    "# net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df06460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_blob_as_input(file_path):\n",
    "    img = cv.imread(file_path)\n",
    "    return cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08117e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, ln, blob):\n",
    "    net.setInput(blob)\n",
    "    return net.forward(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4f96871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_people_detected(outputs):\n",
    "    count = 0\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.25 and classID == 0:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def run_inference_and_get_count(images):\n",
    "    c = 0\n",
    "    data = {}\n",
    "    for i, each_image in enumerate(images):\n",
    "        if i % 50 == 0:\n",
    "            print(f'Completed: {i}')\n",
    "        blob = get_image_blob_as_input(each_image)\n",
    "        outputs = predict(net, ln, blob)\n",
    "        c += get_number_of_people_detected(outputs)\n",
    "        data[each_image] = c\n",
    "    return c, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a56c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_BASE = '/home/rdr2143/waymo-adv-dataset/adv/og/'\n",
    "PATCHED_BASE = '/home/rdr2143/waymo-adv-dataset/adv/patched/'\n",
    "og_images = [OG_BASE + x for x in os.listdir(OG_BASE)]\n",
    "patched_images = [PATCHED_BASE + x for x in os.listdir(PATCHED_BASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dde837c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0\n",
      "Completed: 50\n",
      "Completed: 100\n",
      "Completed: 150\n",
      "Completed: 200\n",
      "Completed: 250\n",
      "Completed: 300\n",
      "Completed: 350\n",
      "Completed: 400\n",
      "Completed: 450\n",
      "Completed: 500\n",
      "Completed: 550\n",
      "Completed: 600\n",
      "Completed: 650\n",
      "Completed: 700\n",
      "Completed: 750\n",
      "Completed: 800\n",
      "Completed: 850\n",
      "Completed: 900\n",
      "Completed: 950\n",
      "Completed: 0\n",
      "Completed: 50\n",
      "Completed: 100\n",
      "Completed: 150\n",
      "Completed: 200\n",
      "Completed: 250\n",
      "Completed: 300\n",
      "Completed: 350\n",
      "Completed: 400\n",
      "Completed: 450\n",
      "Completed: 500\n",
      "Completed: 550\n",
      "Completed: 600\n",
      "Completed: 650\n",
      "Completed: 700\n",
      "Completed: 750\n",
      "Completed: 800\n",
      "Completed: 850\n",
      "Completed: 900\n",
      "Completed: 950\n"
     ]
    }
   ],
   "source": [
    "patched_people, patched_data = run_inference_and_get_count(patched_images)\n",
    "og_people, og_data = run_inference_and_get_count(og_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c959a294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/home/rdr2143/waymo-adv-dataset/adv/patched/131_patched_img.jpg': 1,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/285_patched_img.jpg': 1,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/367_patched_img.jpg': 3,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/290_patched_img.jpg': 4,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/617_patched_img.jpg': 5,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/562_patched_img.jpg': 6,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/393_patched_img.jpg': 6,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/46_patched_img.jpg': 6,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/362_patched_img.jpg': 6,\n",
       " '/home/rdr2143/waymo-adv-dataset/adv/patched/9_patched_img.jpg': 6}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8bd3f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0\n",
      "Completed: 50\n",
      "Completed: 100\n",
      "Completed: 150\n",
      "Completed: 200\n",
      "Completed: 250\n",
      "Completed: 300\n",
      "Completed: 350\n",
      "Completed: 400\n",
      "Completed: 450\n",
      "Completed: 500\n",
      "Completed: 550\n",
      "Completed: 600\n",
      "Completed: 650\n",
      "Completed: 700\n",
      "Completed: 750\n",
      "Completed: 800\n",
      "Completed: 850\n",
      "Completed: 900\n",
      "Completed: 950\n"
     ]
    }
   ],
   "source": [
    "og_people = run_inference_and_get_count(og_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d365e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.74193548387096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched_people/og_people * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e62291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
